{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building Recommendation Engines.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO/eMQPRqO+C8tc3T7toLez",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OliverRevilla/BigData_Pyspark/blob/main/Building_Recommendation_Engines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJExhCn7aU8k"
      },
      "source": [
        "# **Data Preparation for Spark ALS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aLDAkgAotvW"
      },
      "source": [
        "from pysaprk.sql.functions import monotically_increasing_id\n",
        "users = users.coalesce(1)\n",
        "users = users.withColumn(\n",
        "    'userId', monotically_increasing_id()).persist()\n",
        ")\n",
        "\n",
        "#--------------------------------------------------------------\n",
        "# Import monotonically_increasing_id and show R\n",
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "R.show()\n",
        "\n",
        "\n",
        "# Use the to_long() function to convert the dataframe to the \"long\" format.\n",
        "ratings = to_long(R)\n",
        "ratings.show()\n",
        "\n",
        "# Get unique users and repartition to 1 partition\n",
        "users = ratings.select(\"User\").distinct().coalesce(1)\n",
        "\n",
        "# Create a new column of unique integers called \"userId\" in the users dataframe.\n",
        "users = users.withColumn(\"userId\", monotonically_increasing_id()).persist()\n",
        "users.show()\n",
        "\n",
        "# Extract the distinct movie id's\n",
        "movies = ratings.select(\"Movie\").distinct() \n",
        "\n",
        "# Repartition the data to have only one partition.\n",
        "movies = movies.coalesce(1) \n",
        "\n",
        "# Create a new column of movieId integers. \n",
        "movies = movies.withColumn(\"movieId\", monotonically_increasing_id()).persist() \n",
        "\n",
        "# Join the ratings, users and movies dataframes\n",
        "movie_ratings = ratings.join(users, \"User\", \"left\").join(movies, \"Movie\", \"left\")\n",
        "movie_ratings.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0E9uH1adcLC"
      },
      "source": [
        "## **ALS parameters and hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcMui7_Vdg7q"
      },
      "source": [
        "# Example of ALS model Code\n",
        "als_model = ALS(userCol = 'userID', # Name of column that contains user ID's\n",
        "                itemCol = 'movieID', # Name of column that contains item id's\n",
        "                ratingCol = 'rating', # Name of column that contains ratings\n",
        "                rank = 25, # number of latent features\n",
        "                maxIter = 100, # how many times ALS should iterate \n",
        "                regParam = .05, # Lambda\n",
        "                alpha = 40, # Only used with implicit ratings\n",
        "                nonnegative = True, # Ensures positive numbers\n",
        "                coldStartStrategy = 'drop', # To avoid the coincidence when train set will be equal to test set of one ID.\n",
        "                implicitPrefs = False) # It's neccesary say to pyspark if our data are implicit or explicit\n",
        "\n",
        "# Fit AlS to training dataset\n",
        "model = als.fit(training_data)\n",
        "\n",
        "# Generate predictions on test dataset\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "#--------------------------------------------------------------------------------------------------\n",
        "# Split the ratings dataframe into training and test data\n",
        "(training_data, test_data) = ratings.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Set the ALS hyperparameters\n",
        "from pyspark.ml.recommendation import ALS\n",
        "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", rank =10, maxIter =15, regParam =.1,\n",
        "          coldStartStrategy=\"drop\", nonnegative =True, implicitPrefs = False)\n",
        "\n",
        "# Fit the mdoel to the training_data\n",
        "model = als.fit(training_data)\n",
        "\n",
        "# Generate predictions on the test_data\n",
        "test_predictions = model.transform(test_data)\n",
        "test_predictions.show()\n",
        "\n",
        "# Import RegressionEvaluator\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Complete the evaluator code\n",
        "evaluator = RegressionEvaluator(metricName=\"RMSE\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
        "\n",
        "# Extract the 3 parameters\n",
        "print(evaluator.getMetricName())\n",
        "print(evaluator.getLabelCol())\n",
        "print(evaluator.getPredictionCol())\n",
        "\n",
        "# Evaluate the \"test_predictions\" dataframe\n",
        "RMSE = evaluator.evaluate(test_predictions)\n",
        "\n",
        "# Print the RMSE\n",
        "print (RMSE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q5mfq5tnYG_"
      },
      "source": [
        "## **Recommending algorithm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OombbVo0oHwv"
      },
      "source": [
        "### **Sparsity**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow1LG_1infzZ"
      },
      "source": [
        "# Number of ratings in matrix\n",
        "numerator = ratings.count()\n",
        "\n",
        "# Distinct users and movies\n",
        "users = ratings.select(\"userId\").distinct().count()\n",
        "movies = ratings.select('movieId').distinct().count()\n",
        "\n",
        "# Number of ratings matrix could contain if no empty cells\n",
        "denominator = users*movies\n",
        "\n",
        "# Calculating sparsity\n",
        "sparsity = 1 - (numerator*0.8/denominator)\n",
        "\n",
        "print(\"Sparsity: \"), sparsity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koeiSfH7M3Kf"
      },
      "source": [
        "### **ALS model buildout**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3bQbP6oNDzP"
      },
      "source": [
        "# It is useful when someone want to test other parameters for the model to improve the metrics\n",
        "#ParamGridBuilder()\n",
        "\n",
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "param_grid = ParamGridBuilder()\n",
        "                      .addGrid(als.rank, [5,40,80,120])\n",
        "                      .addGrid(als.maxIter, [5,100,250,500])\n",
        "                      .addGrid(als.regParam, [.05,.1,1.5])\n",
        "                      .build()\n",
        "\n",
        "#CrossValidator()\n",
        "from pyspark.ml.tuning import CrossValidator\n",
        "cv = CrossValidator(estimator = als,\n",
        "                    estimatorParamMaps = param_grid,\n",
        "                    evaluator = evaluator,\n",
        "                    numFolds = 5)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS3iGApJMW7C"
      },
      "source": [
        "# Complete Code\n",
        "\n",
        "# Create training and test set (80/20 split)\n",
        "(training, test) = movie_ratings.randomSplit([0.8,0.2])\n",
        "\n",
        "# Build generic ALS model without hyperparameters\n",
        "from pyspark.ml.recommendation import ALS\n",
        "als = ALS(userCol = \"userId\",\n",
        "          itemCol = \"movieId\",\n",
        "          ratingCol = \"rating\",\n",
        "          coldStartStrategy = \"drop\",\n",
        "          nonnegative = True,\n",
        "          implicitPrefs = False)\n",
        "\n",
        "# Tell Spark what values to try for each hyperparameter\n",
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "param_grid = ParamGridBuilder()\n",
        "                    .addGrid(als.rank, [5,40,80,120])\n",
        "                    .addGrid(als.maxIter, [5,100,250,500])\n",
        "                    .addGrid(als.regParam, [.05,.1,1.5])\n",
        "                    .build()\n",
        "\n",
        "# Tell Spark how to evaluate model performance\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "evaluator = RegressionEvaluator(metricName = \"rmse\", labelCol = \"rating\",\n",
        "                                predictionCol = \"prediction \")\n",
        "\n",
        "# Build cross validation step using CrossValidator\n",
        "from pyspark.ml.tuning import CrossValidator\n",
        "cv = CrossValidator(estimator = als,\n",
        "                    estimatorParamMaps = param_grid,\n",
        "                    evaluator = evaluator,\n",
        "                    numFolds = 5)\n",
        "\n",
        "# Run the cv on the training data\n",
        "model = cv.fit(training)\n",
        "\n",
        "# Extract best combination of values from cross Validation\n",
        "best_model = model.bestModel\n",
        "\n",
        "# Generate test set predictions and evaluate using RMSE\n",
        "predictions = best_model.transform(test)\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "\n",
        "# Print evaluation metrics and model parameters\n",
        "print(\"**Best Model**\")\n",
        "print(\"RMSE = \"), rmse\n",
        "print(\" Rank: \"), best_model.rank\n",
        "print(\" MaxIter: \"), best_model._java_obj.parent().getMaxIter()\n",
        "print(\" RegParam: \"), best_model._java_obj.parent().getRegParam()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuSfH-5iQzy6"
      },
      "source": [
        "# Import the required functions\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "\n",
        "# Create test and train set\n",
        "(train, test) = ratings.randomSplit([0.8, 0.2], seed = 1234)\n",
        "\n",
        "# Create ALS model\n",
        "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", nonnegative = True, implicitPrefs = False)\n",
        "\n",
        "# Confirm that a model called \"als\" was created\n",
        "type(als)\n",
        "\n",
        "# Import the requisite items\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "\n",
        "# Add hyperparameters and their respective values to param_grid\n",
        "param_grid = ParamGridBuilder()\\\n",
        "            .addGrid(als.rank,[10,50,100,150])\\\n",
        "            .addGrid(als.maxIter,[5,50,100,200])\\\n",
        "            .addGrid(als.regParam,[.01,.05,.1,.15])\\\n",
        "            .build()           \n",
        "           \n",
        "# Define evaluator as RMSE and print length of evaluator\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\") \n",
        "print (\"Num models to be tested: \", len(param_grid))\n",
        "\n",
        "# Build cross validation using CrossValidator\n",
        "cv = CrossValidator(estimator=als, estimatorParamMaps = param_grid, evaluator= evaluator, numFolds= 5)\n",
        "\n",
        "# Confirm cv was built\n",
        "print(cv)\n",
        "\n",
        "# Print best_model\n",
        "print(type(best_model))\n",
        "\n",
        "# Complete the code below to extract the ALS model parameters\n",
        "print(\"**Best Model**\")\n",
        "\n",
        "# Print \"Rank\"\n",
        "print(\"  Rank:\", best_model.getRank())\n",
        "\n",
        "# Print \"MaxIter\"\n",
        "print(\"  MaxIter:\", best_model.getMaxIter())\n",
        "\n",
        "# Print \"RegParam\"\n",
        "print(\"  RegParam:\", best_model.getRegParam())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fNeBBrC6ypv"
      },
      "source": [
        "### **ALS model without ratings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W4ZU0VM62o5"
      },
      "source": [
        "def add_zeros(df):\n",
        "  # Extracts distinct users\n",
        "  users = df.select(\"userId\").distinct()\n",
        "\n",
        "  # Extracts distinct songs\n",
        "  songs = df.select(\"songId\").distinct()\n",
        "\n",
        "  # Joins users and songs, fills blanks with 0\n",
        "  cross_join = users.crossJoin(songs)\\\n",
        "                    .join(df,['userId','songId'], \"left\").fillna(0)\n",
        "  return cross_join\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHLco4_PGdN9"
      },
      "source": [
        "#  Building several ROEM models\n",
        "\n",
        "(train, test) =  implicit_ratings.randomSplit([.8,.2])\n",
        "# Empty list to be filled with models\n",
        "model_list = []\n",
        "\n",
        "# Complete each of the hyperparameter value list\n",
        "ranks = [10,20,30,40]\n",
        "maxIters = [10,20,30,40]\n",
        "regParams = [.05,.1,.15]\n",
        "alphas = [20,40,60,80]\n",
        "\n",
        "# For loop will automatically create and store ALS models\n",
        "for r in ranks:\n",
        "  for mi in maxIters:\n",
        "    for rp in regParams:\n",
        "      for a in alphas:\n",
        "        model_list.append(ALS(userCol = \"userId\", itemCol = \"songId\",\n",
        "                              ratingCol = \"num_plays\", rank = r, maxIter = mi, regParam = rp,\n",
        "                              alpha = a, coldStartStrategy = \"drop\", nonnegative = True,\n",
        "                              implicitPrefs = True)\n",
        "        \n",
        "# Error output\n",
        "for model in model_list:\n",
        "  # Fits each model to the trainning data\n",
        "  trained_model = model.fit(train)\n",
        "\n",
        "  # Generates test predictions\n",
        "  predictions = trained_model.transform(test)\n",
        "\n",
        "  # Evaluates each  model's performance\n",
        "  ROEM(predictions)\n",
        "\n",
        "\n",
        "### -----------------------------------------------------------------------------\n",
        "  # For loop will automatically create and store ALS models\n",
        "for r in ranks:\n",
        "    for mi in maxIters:\n",
        "        for rp in regParams:\n",
        "            for a in alphas:\n",
        "                model_list.append(ALS(userCol= \"userId\", itemCol= \"songId\", ratingCol= \"num_plays\", rank = r, maxIter = mi, regParam = rp, alpha = a, coldStartStrategy=\"drop\", nonnegative = True, implicitPrefs = True))\n",
        "\n",
        "# Print the model list, and the length of model_list\n",
        "print (model_list, \"Length of model_list: \", len(model_list))\n",
        "\n",
        "# Validate\n",
        "len(model_list) == (len(ranks)*len(maxIters)*len(regParams)*len(alphas))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsrMiy3zRCXS"
      },
      "source": [
        "# View user 26's original ratings\n",
        "print (\"User 26 Original Ratings:\")\n",
        "original_ratings.filter(col(\"userId\") == 26).show()\n",
        "\n",
        "# View user 26's recommendations\n",
        "print (\"User 26 Recommendations:\")\n",
        "binary_recs.filter(col(\"userId\") == 26).show()\n",
        "\n",
        "# View user 99's original ratings\n",
        "print (\"User 99 Original Ratings:\")\n",
        "original_ratings.filter(col(\"userId\") == 99).show()\n",
        "\n",
        "# View user 99's recommendations\n",
        "print (\"User 99 Recommendations:\")\n",
        "binary_recs.filter(col(\"userId\") == 99).show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}